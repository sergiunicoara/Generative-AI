# LinkedIn Post â€” copy-paste ready (Unicode bold renders correctly on LinkedIn)

---

ğ— ğ—¼ğ˜€ğ˜ ğ˜ƒğ—²ğ—°ğ˜ğ—¼ğ—¿ ğ——ğ—• ğ—¯ğ—²ğ—»ğ—°ğ—µğ—ºğ—®ğ—¿ğ—¸ğ˜€ ğ—®ğ—¿ğ—² ğ—ºğ—²ğ—®ğ˜€ğ˜‚ğ—¿ğ—¶ğ—»ğ—´ ğ—® ğ—³ğ—®ğ—»ğ˜ğ—®ğ˜€ğ˜†.

They test on random vectors.
Production RAG systems run on real text â€” clustered, overlapping, and full of hard negatives.

I ran a full stress test on 4 engines:
Qdrant, Elasticsearch, Redis, pgvector

20,000 real Wikipedia embeddings. Here's what actually matters in production.

All tests: same hardware, warm caches, fixed embedding model, identical HNSW parameters.

â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•

ğŸš€ Speed under load
(single node, 20k vectors, independent clients)

Redis peaks at ğŸµğŸ­ğŸ´ req/sec.
pgvector reaches ğŸ­ğŸ²ğŸ°.
Qdrant ğŸ­ğŸ®ğŸ¬.
Elasticsearch ğŸ²ğŸ­ â€” on a single node.

Yes, Elasticsearch scales horizontally.
But most small-to-mid RAG deployments start on one node â€” and that's where Redis wins without extra infrastructure.

ğ—¢ğ—»ğ—² ğ˜ğ—µğ—¶ğ—»ğ—´ ğ˜ğ—µğ—®ğ˜ ğ˜€ğ˜‚ğ—¿ğ—½ğ—¿ğ—¶ğ˜€ğ—²ğ—± ğ—ºğ—²:
pgvector's single-thread latency dropped from ~ğŸ±ğŸ´ğ—ºğ˜€ to ğŸ­ğŸ´ğ—ºğ˜€ once each client used a persistent connection instead of reconnecting per query.

The old number was penalising connection overhead, not search quality.

â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•

ğŸ¯ Will it find the right answer?

On fake benchmark data, all engines hit ğŸ­ğŸ¬ğŸ¬% recall.

On real data?
Redis and pgvector cap at ~ğŸµğŸµ.ğŸ´% recall under standard HNSW build params (m=16, ef_construction=100).

Real topics create "hard negatives" that are genuinely difficult to resolve without rebuilding the index with higher-quality params.

â†’ That's real users occasionally getting the wrong document â€” worth knowing before you go live.

â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•

âœï¸ What happens when your index gets updated?

Every production RAG system has continuous writes â€” new documents, deletions, updates.

At our test scale (10k â†’ 15k vectors with deletes), Elasticsearch latency jumped +ğŸ°ğŸ°%.

Redis and Qdrant actually got faster â€” their internal graph rebalancing improved traversal at this size.

â†’ This is the test nobody runs before going live.

â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•

ğŸ” Using a reranker (cross-encoder)?

With a ğŸ±ğŸ¬ğ—ºğ˜€ reranker in the pipeline:
â€¢ Redis: ğŸ±ğŸ±ğ—ºğ˜€ end-to-end
â€¢ Elasticsearch: ğŸ­ğŸ±ğŸ´ğ—ºğ˜€ end-to-end

When your reranker is slow (â‰¥30ms), it dominates the latency budget.
Fast retrieval still matters â€” it compounds.

If you swap in a ğŸ±ğ—ºğ˜€ reranker, engine choice suddenly matters a lot more again.

â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•

The practical takeaway

â€¢ ğ—›ğ—¶ğ—´ğ—µ ğ˜ğ—¿ğ—®ğ—³ğ—³ğ—¶ğ—°, ğ˜€ğ—¶ğ—»ğ—´ğ—¹ğ—² ğ—»ğ—¼ğ—±ğ—², ğ—°ğ—¼ğ—¿ğ—½ğ˜‚ğ˜€ ğ—³ğ—¶ğ˜ğ˜€ ğ—¶ğ—» ğ—¥ğ—”ğ— ?
â†’ Redis â€” blazing fast, minimal infra (watch memory pressure as you scale)

â€¢ ğ—¡ğ—²ğ—²ğ—± ğ˜ğ—µğ—² ğ—¯ğ—²ğ˜€ğ˜ ğ—¿ğ—²ğ—°ğ—®ğ—¹ğ—¹ + ğ—¿ğ—²ğ—¹ğ—¶ğ—®ğ—¯ğ—¶ğ—¹ğ—¶ğ˜ğ˜†?
â†’ Qdrant â€” strong quality on real data, stable under index churn

â€¢ ğ—”ğ—¹ğ—¿ğ—²ğ—®ğ—±ğ˜† ğ—¿ğ˜‚ğ—»ğ—»ğ—¶ğ—»ğ—´ ğ—£ğ—¼ğ˜€ğ˜ğ—´ğ—¿ğ—²ğ˜€?
â†’ pgvector â€” zero new infrastructure, fragmentation-neutral; a reranker closes most of the latency gap

â€¢ ğ—”ğ—¹ğ—¿ğ—²ğ—®ğ—±ğ˜† ğ—¼ğ—» ğ˜ğ—µğ—² ğ—˜ğ—¹ğ—®ğ˜€ğ˜ğ—¶ğ—° ğ˜€ğ˜ğ—®ğ—°ğ—¸ (ğ—ºğ˜‚ğ—¹ğ˜ğ—¶-ğ—»ğ—¼ğ—±ğ—²)?
â†’ Elasticsearch â€” throughput scales out, but watch write fragmentation per shard

â€¢ ğ—”ğ—±ğ—±ğ—¶ğ—»ğ—´ ğ—® ğ—¿ğ—²ğ—¿ğ—®ğ—»ğ—¸ğ—²ğ—¿ â‰¥ğŸ¯ğŸ¬ğ—ºğ˜€?
â†’ Retrieval speed still compounds â€” don't ignore it

â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•

Full benchmark open source on GitHub: [link]

ğ—ªğ—µğ—®ğ˜ ğ˜ƒğ—²ğ—°ğ˜ğ—¼ğ—¿ ğ——ğ—• ğ—®ğ—¿ğ—² ğ˜†ğ—¼ğ˜‚ ğ—¿ğ˜‚ğ—»ğ—»ğ—¶ğ—»ğ—´ ğ—¶ğ—» ğ—½ğ—¿ğ—¼ğ—±ğ˜‚ğ—°ğ˜ğ—¶ğ—¼ğ—»?
Curious what tradeoffs you've hit ğŸ‘‡

#RAG #vectordatabases #LLM #AIengineering #machinelearning
